{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" >\n",
    "    <img src = '../../docs/logo.png' height = \"200\">\n",
    "<p>\n",
    "\n",
    "# Report - 20th Noveber - MoCap Rasp: Camera Calibration\n",
    "> Mateus Pincho de Oliveira\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruir a matriz de câmera \n",
    "\n",
    "A intenção de usar o Coppelia é de que seja possível conhecer as características da câmera e a sua posição no espaço para que seja possível reconstruir a matriz de câmera $C$, que rege a projeção dos pontos $3$-D no plano da imagem.\n",
    "\n",
    "Para reconstruí-la, é preciso conhecer a matriz de câmera $K$: \n",
    "\n",
    "$$ K = \\begin{bmatrix}\n",
    "f_x&0 &O_x \\\\\n",
    "0& f_y&O_y \\\\\n",
    "0& 0&1\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "O ponto principal está no centro da imagem, que podemos definir no Coppelia. Não é possível definir diretamente a distância focal do sensor visual no Coppelia, mas a partir do *angle of view* eu conheço qual é a distância focal\n",
    "\n",
    "$$ \\alpha = 2\\cdot\\text{atan}(\\frac{d}{2f}) $$\n",
    "\n",
    "Para encontrar a posição e orientação do sensor visual, eu utilizo a função da API `sim.getObjectMatrix()`, que me retorna a matriz de transformação do Handle em relação ao mundo. É preciso apenas se atentar na referência dos eixos coordenados, que é diferente entre o Coppelia e na definição da matriz de câmera. \n",
    "\n",
    "Dessa forma, é preciso transformar os eixos do Coppelia para que eles coincidam com a formalização matemática. \n",
    "\n",
    "<p align = \"center\" >\n",
    "    <img src = '../../docs/axis.jpeg' height = \"300\">\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
