{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera calibration Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librarys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "from coppeliasim_zmqremoteapi_client import RemoteAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoppeliaSim Scene config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect and configure the simulation \n",
    "client = RemoteAPIClient()\n",
    "sim = client.getObject('sim')\n",
    "\n",
    "# When simulation is not running, ZMQ message handling could be a bit\n",
    "# slow, since the idle loop runs at 8 Hz by default. So let's make\n",
    "# sure that the idle loop runs at full speed for this program:\n",
    "defaultIdleFps = sim.getInt32Param(sim.intparam_idle_fps)   \n",
    "sim.setInt32Param(sim.intparam_idle_fps, 0)\n",
    "\n",
    "# Get the vision sensor handle\n",
    "visionSensorHandle = sim.getObject('/Vision_sensor')\n",
    "cubo = sim.getObject('/Cuboid[3]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover camera parameters from scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isZhang = False\n",
    "\n",
    "# Vision sensor internal parameters\n",
    "# Run this before to adjust the perspective angle\n",
    "def get_perspective_angle(focal_length, sensor_size):\n",
    "    perspective_angle = 2*math.atan(sensor_size / (2*focal_length))\n",
    "    perspective_angle = perspective_angle*(180/math.pi)\n",
    "    print(perspective_angle)\n",
    "    return perspective_angle\n",
    "\n",
    "get_perspective_angle(3.04,3.68)\n",
    "\n",
    "focal_length = 3.04\n",
    "# Defined in vision sensor parameters\n",
    "image_size = (1280,720)\n",
    "\n",
    "# Pixel density defined by the sensor resolution\n",
    "pixel_density = (830,829)\n",
    "\n",
    "# Cria a matriz K\n",
    "k_matrix = np.array([[focal_length*pixel_density[0], 0, image_size[0]/2],\n",
    "                    [0, focal_length*pixel_density[1], image_size[1/2]],\n",
    "                    [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "# Start simulation in CoppeliaSim\n",
    "sim.startSimulation()\n",
    "\n",
    "# Get Vision_sensor transformation matrix\n",
    "transformation_matrix = sim.getObjectMatrix(visionSensorHandle, -1)\n",
    "\n",
    "sim.stopSimulation()\n",
    "\n",
    "# Transforma a transformation_matrix em numpy\n",
    "\n",
    "# Cria a matriz de câmera C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the calibration images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start simulation in CoppeliaSim\n",
    "sim.startSimulation()\n",
    "\n",
    "# index of the calibration image\n",
    "n = 1\n",
    "\n",
    "# See the Vision sensor image\n",
    "while (t := sim.getSimulationTime()) < 10:\n",
    "    img, resX, resY = sim.getVisionSensorCharImage(visionSensorHandle)\n",
    "    img = np.frombuffer(img, dtype=np.uint8).reshape(resY, resX, 3)\n",
    "    # In CoppeliaSim images are left to right (x-axis), and bottom to top (y-axis)\n",
    "    # (consistent with the axes of vision sensors, pointing Z outwards, Y up)\n",
    "    # and color format is RGB triplets, whereas OpenCV uses BGR:\n",
    "    img = cv2.flip(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), 0)\n",
    "    #cv2.imshow('', img)\n",
    "    #cv2.waitKey(1)\n",
    "\n",
    "    p=sim.getObjectPosition(cubo,-1)\n",
    "\n",
    "    print(p, transformation_matrix,'\\n','\\n')\n",
    "    time.sleep(0.75)\n",
    "\n",
    "    cv2.imwrite(f'image{n}.jpg',img)\n",
    "\n",
    "sim.stopSimulation()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "sim.stopSimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract world points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isZhang: \n",
    "    patternSize = (7,7)\n",
    "    squareSize = (10)\n",
    "    imgSize = (1280,720)\n",
    "\n",
    "    def construct3DPoints(patternSize,squareSize):\n",
    "        X = np.zeros((patternSize[0]*patternSize[1],3), np.float32)\n",
    "        X[:,:2] = np.mgrid[0:patternSize[0],0:patternSize[1]].T.reshape(-1,2)\n",
    "        X = X * squareSize\n",
    "        return X\n",
    "\n",
    "    boardPoints = construct3DPoints(patternSize,squareSize)\n",
    "    worldPoints = []\n",
    "\n",
    "else: \n",
    "    worldPoints = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isZhang:\n",
    "    counter = 0\n",
    "    imagePoints = []\n",
    "    images = glob.glob('../calibration-images/*.jpg')\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCornersSB(gray, patternSize, None)\n",
    "        if ret == True:\n",
    "            print(\"Corners found in image\" + str(fname)) #- see if corners are found \n",
    "            imagePoints.append(corners)\n",
    "            worldPoints.append(boardPoints)\n",
    "            counter+=1\n",
    "\n",
    "    print(\"using \" + str(counter) + \" images\")\n",
    "\n",
    "else: \n",
    "    img = cv2.imread('image.jpg') \n",
    "  \n",
    "    # convert image to gray scale image \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    # detect corners with the goodFeaturesToTrack function. \n",
    "    corners = cv2.goodFeaturesToTrack(gray, 27, 0.01, 10) \n",
    "    corners = np.int0(corners) \n",
    "\n",
    "    print(corners)\n",
    "    \n",
    "    # we iterate through each corner,  \n",
    "    # making a circle at each point that we think is a corner. \n",
    "    for i in corners: \n",
    "        x, y = i.ravel() \n",
    "        cv2.circle(img, (x, y), 3, 255, -1) \n",
    "    \n",
    "    plt.imshow(img), plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the camera matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isZhang: \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    flagsCalib = cv2.CALIB_RATIONAL_MODEL\n",
    "    ret, cameraMatrix, k, rvecs, tvecs = cv2.calibrateCamera(worldPoints, imagePoints, imgSize, None, None,flags=flagsCalib)\n",
    "\n",
    "    print(\"Using \"+str(counter)+\" of \"+str(len(images))+\" images\")\n",
    "    print(\"RMS re-projection error:\", ret)\n",
    "    print(\"Camera Matrix:\\n\", cameraMatrix)\n",
    "    print(\"Distortion Parameters:\\n\", k)\n",
    "    \n",
    "else: \n",
    "\n",
    "    def calibrate_camera(world_points, image_points):\n",
    "        \"\"\"\n",
    "        Função para encontrar a matriz de câmera C usando o algoritmo DLT.\n",
    "        \n",
    "        Args: \n",
    "            world_points: Array de pontos 3D na cena.\n",
    "            image_points: Array de pontos 2D projetados na imagem.\n",
    "\n",
    "        Return: \n",
    "            C_matrix: numpy array contendo a matriz de câmera estimada. \n",
    "        \"\"\"\n",
    "\n",
    "        if len(world_points) != len(image_points): \n",
    "            raise ValueError(\"Must be the same number of World points and Image points\")\n",
    "        \n",
    "        if len(world_points) < 6 | len(image_points) < 6 :\n",
    "            raise ValueError(\"Must have a minimum of 6 points to compute the camera matrix\")\n",
    "\n",
    "\n",
    "        Q = []\n",
    "        for i in range(len(world_points)):\n",
    "            X, Y, Z = world_points[i]\n",
    "            u,v  = image_points[i]\n",
    "            Q.append([X, Y, Z, 1, 0, 0, 0, 0, -u*X, -u*Y, -u*Z, -u])\n",
    "            Q.append([0, 0, 0, 0, X, Y, Z, 1, -v*X, -v*Y, -v*Z, -v])\n",
    "\n",
    "        Q = np.array(Q)\n",
    "        #print(Q)\n",
    "\n",
    "        # Resolva o sistema de equações usando SVD\n",
    "        _, _, V = svd(Q)\n",
    "        c = V[-1, :12]\n",
    "        #print(c)\n",
    "\n",
    "        # Reconstrua a matriz de projeção da câmera\n",
    "        C_matrix = c.reshape(3, 4)\n",
    "        print(C_matrix)\n",
    "\n",
    "        return C_matrix\n",
    "    \n",
    "    camera_matrix = calibrate_camera(worldPoints,imagePoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots and stuff like that"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
