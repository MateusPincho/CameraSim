{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera calibration Sim\n",
    "\n",
    "Objective: know the camera calibration info to reconstruct the camera matrix. \n",
    "\n",
    "The mapping between a world point $P$ and your projection $p$ in the image plane is described by: \n",
    "\n",
    "$$ \\tilde{p} = M_{int} \\cdot M_{ext} \\cdot \\tilde{P} $$\n",
    "\n",
    "Where: \n",
    "\n",
    "$$ M_{int} = \\begin{bmatrix}\n",
    "f_x&0 &O_x \\\\\n",
    "0& f_y&O_y \\\\\n",
    "0& 0&1\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "and \n",
    "\n",
    "$$ M_{ext} = \\begin{bmatrix}\n",
    "r_{11}&r_{12}  &r_{13} & t_x \\\\ r_{21} &r_{22} &r_{23}&t_y \\\\ r_{31}&r_{32} &r_{33}  & t_z\\\\ 0&0&0&1\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "$M_{int}$ represents the internal parameters of the camera. \n",
    "- $(f_x,f_y)$ are the focal distance in pixels, in the $x$ and $y$ directions\n",
    "- $(O_x,O_y)$ is the principal point \n",
    "\n",
    "$M_{ext}$ represents the position and orientation of the camera in the world coordinate frame \n",
    "\n",
    "---\n",
    "\n",
    "### This parameters must be recovers this parameters from the simulation. \n",
    "\n",
    "The internal parameters must be recover from the vision sensor properties. \n",
    "\n",
    "<p align = \"center\">\n",
    "    <img src = '../vision-sensor.jpeg'>\n",
    "</p>\n",
    "\n",
    "**Fist problem:** Cannot set the focal length.\n",
    "- Use the perspective angle to set the focal length.\n",
    "- $ \\alpha = 2\\cdot\\text{atan}(\\frac{d}{2f})$, where $\\alpha$ is the perspective angle, $d$ is the sensor size and $f$ is the focal length.\n",
    "- This parameters can be recovered from the Raspberry Pi Camera V2 Documentation. \n",
    "\n",
    "**Second problem:** Cannot know the pixel density.\n",
    "- The $K$ is definied using the focal lenght in pixels units, not in milimeters. \n",
    "- To convert, it's necessary to know the pixel density of the vision sensor. \n",
    "- Set to the pixel density of the V2 Cam? \n",
    "\n",
    "--- \n",
    "\n",
    "The camera extrinsic parameters are recovered from the simulation using `sim.getObjectMatrix()`. This function returns the position and orientation of an object in relation to another\n",
    "\n",
    "<p align = \"center\">\n",
    "    <img src = '../object-matrix.jpeg'>\n",
    "</p>\n",
    "\n",
    "Your arguments are: \n",
    "- objectHandle\n",
    "- relativeToObjectHandle: indicates relative to which reference frame the matrix is specified.\n",
    "    - Specify sim.handle_world to set the absolute transformation matrix, sim.handle_inverse to set the inverse of the absolute transformation matrix, sim.handle_parent to set the transformation matrix relative to the object's parent, or an object handle relative to whose reference frame the transformation matrix is specified. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librarys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "from coppeliasim_zmqremoteapi_client import RemoteAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoppeliaSim Scene config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect and configure the simulation \n",
    "client = RemoteAPIClient()\n",
    "sim = client.getObject('sim')\n",
    "\n",
    "# When simulation is not running, ZMQ message handling could be a bit\n",
    "# slow, since the idle loop runs at 8 Hz by default. So let's make\n",
    "# sure that the idle loop runs at full speed for this program:\n",
    "defaultIdleFps = sim.getInt32Param(sim.intparam_idle_fps)   \n",
    "sim.setInt32Param(sim.intparam_idle_fps, 0)\n",
    "\n",
    "# Get the vision sensor handle\n",
    "visionSensorHandle = sim.getObject('/Vision_sensor')\n",
    "cubo = sim.getObject('/Cuboid[3]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover camera parameters from scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.369949317476774\n",
      "[[2.52320e+03 0.00000e+00 6.40000e+02]\n",
      " [0.00000e+00 2.52016e+03 3.60000e+02]\n",
      " [0.00000e+00 0.00000e+00 1.00000e+00]]\n",
      "[[-1.00000000e+00 -8.27292428e-13 -2.06823107e-13 -4.55348106e-01]\n",
      " [-2.06823107e-13 -1.03472786e-13  1.00000000e+00 -1.36104780e+00]\n",
      " [-8.27292428e-13  1.00000000e+00  1.03472786e-13  6.58429641e-01]]\n",
      "[[-2.52320000e+03  6.40000000e+02 -4.55633481e-10 -7.27539370e+02]\n",
      " [-8.19052596e-10  3.60000000e+02  2.52016000e+03 -3.19302355e+03]\n",
      " [-8.27292428e-13  1.00000000e+00  1.03472786e-13  6.58429641e-01]]\n"
     ]
    }
   ],
   "source": [
    "isZhang = False\n",
    "\n",
    "# Vision sensor internal parameters\n",
    "# Run this before to adjust the perspective angle\n",
    "def get_perspective_angle(focal_length, sensor_size):\n",
    "    perspective_angle = 2*math.atan(sensor_size / (2*focal_length))\n",
    "    perspective_angle = perspective_angle*(180/math.pi)\n",
    "    print(perspective_angle)\n",
    "    return perspective_angle\n",
    "\n",
    "get_perspective_angle(3.04,3.68)\n",
    "\n",
    "focal_length = 3.04\n",
    "# Defined in vision sensor parameters\n",
    "image_size = (1280,720)\n",
    "\n",
    "# Pixel density defined by the sensor resolution\n",
    "pixel_density = (830,829)\n",
    "\n",
    "# Cria a matriz K\n",
    "k_matrix = np.array([[focal_length*pixel_density[0], 0, image_size[0]/2],\n",
    "                    [0, focal_length*pixel_density[1], image_size[1]/2],\n",
    "                    [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "# Start simulation in CoppeliaSim\n",
    "sim.startSimulation()\n",
    "\n",
    "# Get Vision_sensor transformation matrix\n",
    "transformation_matrix = sim.getObjectMatrix(visionSensorHandle, -1)\n",
    "\n",
    "transformation_matrix = np.array(transformation_matrix).reshape(3,4)\n",
    "\n",
    "sim.stopSimulation()\n",
    "\n",
    "# Cria a matriz de câmera C\n",
    "camera_matrix = k_matrix @ transformation_matrix\n",
    "print(camera_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the calibration images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start simulation in CoppeliaSim\n",
    "sim.startSimulation()\n",
    "\n",
    "# index of the calibration image\n",
    "n = 1\n",
    "\n",
    "# See the Vision sensor image\n",
    "while (t := sim.getSimulationTime()) < 10:\n",
    "    img, resX, resY = sim.getVisionSensorCharImage(visionSensorHandle)\n",
    "    img = np.frombuffer(img, dtype=np.uint8).reshape(resY, resX, 3)\n",
    "    # In CoppeliaSim images are left to right (x-axis), and bottom to top (y-axis)\n",
    "    # (consistent with the axes of vision sensors, pointing Z outwards, Y up)\n",
    "    # and color format is RGB triplets, whereas OpenCV uses BGR:\n",
    "    img = cv2.flip(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), 0)\n",
    "    #cv2.imshow('', img)\n",
    "    #cv2.waitKey(1)\n",
    "\n",
    "    p=sim.getObjectPosition(cubo,-1)\n",
    "\n",
    "    print(p, transformation_matrix,'\\n','\\n')\n",
    "    time.sleep(0.75)\n",
    "\n",
    "    cv2.imwrite(f'image{n}.jpg',img)\n",
    "\n",
    "sim.stopSimulation()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "sim.stopSimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract world points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isZhang: \n",
    "    patternSize = (7,7)\n",
    "    squareSize = (10)\n",
    "    imgSize = (1280,720)\n",
    "\n",
    "    def construct3DPoints(patternSize,squareSize):\n",
    "        X = np.zeros((patternSize[0]*patternSize[1],3), np.float32)\n",
    "        X[:,:2] = np.mgrid[0:patternSize[0],0:patternSize[1]].T.reshape(-1,2)\n",
    "        X = X * squareSize\n",
    "        return X\n",
    "\n",
    "    boardPoints = construct3DPoints(patternSize,squareSize)\n",
    "    worldPoints = []\n",
    "\n",
    "else: \n",
    "    worldPoints = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isZhang:\n",
    "    counter = 0\n",
    "    imagePoints = []\n",
    "    images = glob.glob('../calibration-images/*.jpg')\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCornersSB(gray, patternSize, None)\n",
    "        if ret == True:\n",
    "            print(\"Corners found in image\" + str(fname)) #- see if corners are found \n",
    "            imagePoints.append(corners)\n",
    "            worldPoints.append(boardPoints)\n",
    "            counter+=1\n",
    "\n",
    "    print(\"using \" + str(counter) + \" images\")\n",
    "\n",
    "else: \n",
    "    img = cv2.imread('image.jpg') \n",
    "  \n",
    "    # convert image to gray scale image \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    # detect corners with the goodFeaturesToTrack function. \n",
    "    corners = cv2.goodFeaturesToTrack(gray, 27, 0.01, 10) \n",
    "    corners = np.int0(corners) \n",
    "\n",
    "    print(corners)\n",
    "    \n",
    "    # we iterate through each corner,  \n",
    "    # making a circle at each point that we think is a corner. \n",
    "    for i in corners: \n",
    "        x, y = i.ravel() \n",
    "        cv2.circle(img, (x, y), 3, 255, -1) \n",
    "    \n",
    "    plt.imshow(img), plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the camera matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isZhang: \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    flagsCalib = cv2.CALIB_RATIONAL_MODEL\n",
    "    ret, cameraMatrix, k, rvecs, tvecs = cv2.calibrateCamera(worldPoints, imagePoints, imgSize, None, None,flags=flagsCalib)\n",
    "\n",
    "    print(\"Using \"+str(counter)+\" of \"+str(len(images))+\" images\")\n",
    "    print(\"RMS re-projection error:\", ret)\n",
    "    print(\"Camera Matrix:\\n\", cameraMatrix)\n",
    "    print(\"Distortion Parameters:\\n\", k)\n",
    "    \n",
    "else: \n",
    "\n",
    "    def calibrate_camera(world_points, image_points):\n",
    "        \"\"\"\n",
    "        Função para encontrar a matriz de câmera C usando o algoritmo DLT.\n",
    "        \n",
    "        Args: \n",
    "            world_points: Array de pontos 3D na cena.\n",
    "            image_points: Array de pontos 2D projetados na imagem.\n",
    "\n",
    "        Return: \n",
    "            C_matrix: numpy array contendo a matriz de câmera estimada. \n",
    "        \"\"\"\n",
    "\n",
    "        if len(world_points) != len(image_points): \n",
    "            raise ValueError(\"Must be the same number of World points and Image points\")\n",
    "        \n",
    "        if len(world_points) < 6 | len(image_points) < 6 :\n",
    "            raise ValueError(\"Must have a minimum of 6 points to compute the camera matrix\")\n",
    "\n",
    "\n",
    "        Q = []\n",
    "        for i in range(len(world_points)):\n",
    "            X, Y, Z = world_points[i]\n",
    "            u,v  = image_points[i]\n",
    "            Q.append([X, Y, Z, 1, 0, 0, 0, 0, -u*X, -u*Y, -u*Z, -u])\n",
    "            Q.append([0, 0, 0, 0, X, Y, Z, 1, -v*X, -v*Y, -v*Z, -v])\n",
    "\n",
    "        Q = np.array(Q)\n",
    "        #print(Q)\n",
    "\n",
    "        # Resolva o sistema de equações usando SVD\n",
    "        _, _, V = svd(Q)\n",
    "        c = V[-1, :12]\n",
    "        #print(c)\n",
    "\n",
    "        # Reconstrua a matriz de projeção da câmera\n",
    "        C_matrix = c.reshape(3, 4)\n",
    "        print(C_matrix)\n",
    "\n",
    "        return C_matrix\n",
    "    \n",
    "    camera_matrix = calibrate_camera(worldPoints,imagePoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots and stuff like that"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
