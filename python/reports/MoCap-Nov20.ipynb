{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" >\n",
    "    <img src = '../../docs/logo.png' height = \"200\">\n",
    "<p>\n",
    "\n",
    "# Report - 20th Noveber - MoCap Rasp: Camera Calibration\n",
    "> Mateus Pincho de Oliveira\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruir a matriz de câmera \n",
    "\n",
    "A intenção de usar o Coppelia é de que seja possível conhecer as características da câmera e a sua posição no espaço para que seja possível reconstruir a matriz de câmera $C$, que rege a projeção dos pontos $3$-D no plano da imagem.\n",
    "\n",
    "Para reconstruí-la, é preciso conhecer a matriz de câmera $K$: \n",
    "\n",
    "$$ K = \\begin{bmatrix}\n",
    "f_x&0 &O_x \\\\\n",
    "0& f_y&O_y \\\\\n",
    "0& 0&1\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "O ponto principal está no centro da imagem, que podemos definir no Coppelia. Não é possível definir diretamente a distância focal do sensor visual no Coppelia, mas a partir do *angle of view* eu conheço qual é a distância focal\n",
    "\n",
    "$$ \\alpha = 2\\cdot\\text{atan}(\\frac{d}{2f}) $$\n",
    "\n",
    "---\n",
    "\n",
    "Para encontrar a posição e orientação do sensor visual, eu utilizo a função da API `sim.getObjectMatrix()`, que me retorna a matriz de transformação do Handle em relação ao mundo. É preciso apenas se atentar na referência dos eixos coordenados, que é diferente entre o Coppelia e na definição da matriz de câmera. \n",
    "\n",
    "Dessa forma, é preciso transformar os eixos do Coppelia para que eles coincidam com a formalização matemática. \n",
    "\n",
    "<p align = \"center\" >\n",
    "    <img src = '../../docs/axis.jpeg' height = \"300\">\n",
    "<p>\n",
    "\n",
    "Para verificar se o frame da câmera está de acordo com a formulação matemática, podemos utilizar métodos do Coppelia para alinhar os frames do mundo com o do sensor visual e encontrar a direção do eixo Z do frame de referência da câmera\n",
    "\n",
    "<p align = \"center\" >\n",
    "    <img src = '../../docs/camera_frame.jpeg' height = \"300\">\n",
    "<p>\n",
    "\n",
    "Isso significa que o eixo Z sai do plano da câmera, o que está de acordo com a formulação matemática do frame da Câmera. \n",
    "\n",
    "Como o reference frame da câmera está de acordo, isso significa que ao encontrar a matriz de rotação e translação do sensor visual em relação à câmera, eles foram obtidos em relação ao frame já rotacionado de forma correta. \n",
    "\n",
    "Outro problema que pode ser é em relação a forma como o coppelia fornece a matriz de transformação, que é uma lista de 12 elementos. \n",
    "\n",
    "--- \n",
    "\n",
    "Verificando a matriz de transformação fornecida pelo Coppelia, as informações batem com os dados vistos no Coppelia e com a formulação matemática da matriz de câmera. \n",
    "\n",
    "Refazendo as multiplicações e colocando os pontos da mesma maneira que na teoria (vetor coluna), ainda encontra-se valores muito distantes da realidade. \n",
    "\n",
    "Isso faz com que comece a se suspeitar da matriz de parâmetros intrínsecos da câmera. \n",
    "\n",
    "Como o Coppelia não projeta as imagens, apenas a renderiza utilizando o OpenGL, torna o processo de formação totalmente diferente da teoria matemática por trás que estou utilizando para criar a matriz de intrínsecos. \n",
    "\n",
    "- Não há um sensor que forma as imagens como nas câmeras convencionais, apenas uma renderização da cena. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
